{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import sklearn as scikit_learn\n",
    "import PersistenceImages.persistence_images as pimg\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import OPTICS\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_npy_data(listfoldertypes, numsims, timestep, dimension, dimensionreduction):\n",
    "    \n",
    "    totalfiles = len(listfoldertypes)*numsims;\n",
    "    dimstring = \"H\" + str(dimension)\n",
    "    listofnparrayg = []\n",
    "    listofnparrayr = []\n",
    "    listofnparraygr = []\n",
    "    \n",
    "    for val in listfoldertypes:\n",
    "        for i in range(1,numsims+1):\n",
    "            filepath = val + \"_\" + str(i) + \"_persimg_serialize\" + \"/\" + str(timestep).zfill(7) + \".npy\"\n",
    "            singlefile = np.load(filepath,allow_pickle = True).item()\n",
    "            dimdatag = singlefile[dimstring][0]\n",
    "            dimdatag = np.nan_to_num(dimdatag)\n",
    "            dimdatar = singlefile[dimstring][1]\n",
    "            dimdatar = np.nan_to_num(dimdatar)\n",
    "            dimdatagr = singlefile[dimstring][2]\n",
    "            dimdatagr = np.nan_to_num(dimdatagr)\n",
    "            listofnparrayg.append(dimdatag)\n",
    "            listofnparrayr.append(dimdatar)\n",
    "            listofnparraygr.append(dimdatagr)\n",
    "            \n",
    "    if(dimensionreduction == \"pca\"):\n",
    "        \n",
    "        listofnparrayg = perform_pca(listofnparrayg)\n",
    "        listofnparrayr = perform_pca(listofnparrayr)\n",
    "        listofnparraygr = perform_pca(listofnparraygr)\n",
    "        \n",
    "    elif(dimensionreduction == \"tsne\"):\n",
    "        \n",
    "        listofnparrayg = perform_tsne(listofnparrayg)\n",
    "        listofnparrayr = perform_tsne(listofnparrayr)\n",
    "        listofnparraygr = perform_tsne(listofnparraygr)\n",
    "        \n",
    "    elif(dimensionreduction == \"mds\"):\n",
    "        \n",
    "        listofnparrayg = perform_mds(listofnparrayg)\n",
    "        listofnparrayr = perform_mds(listofnparrayr)\n",
    "        listofnparraygr = perform_mds(listofnparraygr)\n",
    "        \n",
    "    fulldimdata = np.hstack((listofnparrayg,listofnparrayr))\n",
    "    fulldimdata = np.hstack((fulldimdata,listofnparraygr))\n",
    "\n",
    "    return np.array(fulldimdata)\n",
    "        \n",
    "def unison_shuffled_copies(listoflistshuffled):\n",
    "    \n",
    "    p = np.random.permutation(len(listoflistshuffled[0]))\n",
    "    shuffledlist = []\n",
    "    \n",
    "    for val in listoflistshuffled:\n",
    "        shuffled = val[p]\n",
    "        shuffledlist.append(shuffled)\n",
    "        \n",
    "    return shuffledlist \n",
    "\n",
    "def kmeansclust(h0data, h1data, h2data, useh0, useh1, useh2):\n",
    "    \n",
    "    if(useh0):\n",
    "        kmeans = KMeans(n_clusters=3, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "        pred_y = kmeans.fit_predict(h0data)\n",
    "        return pred_y\n",
    "    \n",
    "    elif(useh1):\n",
    "        kmeans = KMeans(n_clusters=3, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "        pred_y = kmeans.fit_predict(h1data) \n",
    "        return pred_y\n",
    "    \n",
    "    elif(useh2):\n",
    "        kmeans = KMeans(n_clusters=3, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "        pred_y = kmeans.fit_predict(h2data) \n",
    "        return pred_y\n",
    "    \n",
    "def opticsclust(h0data, h1data, h2data, useh0, useh1, useh2):\n",
    "    \n",
    "    if(useh0):\n",
    "        clusterf = OPTICS(min_samples=4).fit(h0data)\n",
    "        return clusterf.labels_\n",
    "    \n",
    "    elif(useh1):\n",
    "        clusterf = OPTICS(min_samples=4).fit(h1data)\n",
    "        return clusterf.labels_\n",
    "    \n",
    "    elif(useh2):\n",
    "        clusterf = OPTICS(min_samples=4).fit(h2data)\n",
    "        return clusterf.labels_\n",
    "    \n",
    "def dbscanclust(h0data, h1data, h2data, useh0, useh1, useh2):\n",
    "    \n",
    "    if(useh0):\n",
    "        clusters = DBSCAN(eps=1.36, min_samples=3).fit(h0data)\n",
    "        return clusters.labels_\n",
    "    \n",
    "    elif(useh1):\n",
    "        clusters = DBSCAN(eps=1.36, min_samples=3).fit(h1data)\n",
    "        return clusters.labels_\n",
    "    \n",
    "    elif(useh2):\n",
    "        clusters = DBSCAN(eps=1.36, min_samples=3).fit(h2data)\n",
    "        return clusters.labels_\n",
    "    \n",
    "def perform_pca(datatochange):\n",
    "    \n",
    "    x = StandardScaler().fit_transform(datatochange)\n",
    "    pca = PCA(n_components=5,svd_solver=\"auto\")\n",
    "    principalComponents = pca.fit_transform(x)\n",
    "    return principalComponents\n",
    "\n",
    "def perform_tsne(datatochange):\n",
    "    \n",
    "    X_embedded = TSNE(n_components=3).fit_transform(datatochange)\n",
    "    return X_embedded;\n",
    "\n",
    "def perform_mds(datatochange):\n",
    "    \n",
    "    embedding = MDS(n_components=5)\n",
    "    X_transformed = embedding.fit_transform(datatochange)\n",
    "    return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizedimgslist0 = get_npy_data([\"DAH_Complete_Sorting\",\"DAH_Lipid_Bilayer\",\"DAH_Two_Phase\"], \n",
    "                                   5, 5000000, 0, \"mds\")\n",
    "vectorizedimgslist1 = get_npy_data([\"DAH_Complete_Sorting\",\"DAH_Lipid_Bilayer\",\"DAH_Two_Phase\"], \n",
    "                                   5, 5000000, 1, \"mds\")\n",
    "vectorizedimgslist2 = get_npy_data([\"DAH_Complete_Sorting\",\"DAH_Lipid_Bilayer\",\"DAH_Two_Phase\"], \n",
    "                                   5, 5000000, 2, \"mds\")\n",
    "\n",
    "labels = np.array([\"CS1\",\"CS2\",\"CS3\",\"CS4\",\"CS5\",\"BL1\",\"BL2\",\"BL3\",\"BL4\",\"BL5\",\"BP1\",\"BP2\",\"BP3\",\"BP4\",\"BP5\"])\n",
    "\n",
    "totalshuffled = unison_shuffled_copies([vectorizedimgslist0, vectorizedimgslist1, vectorizedimgslist2, labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  1,  1,  1,  0,  1,  2, -1,  2,  2,  0,  1,  0,  1])"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opticsclust(totalshuffled[0], totalshuffled[1], totalshuffled[2], True, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 2, 2, 0, 2, 1, 2, 1, 1, 0, 2, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscanclust(totalshuffled[0], totalshuffled[1], totalshuffled[2], True, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 0, 0, 2, 0, 1, 0, 1, 1, 2, 0, 2, 0])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeansclust(totalshuffled[0], totalshuffled[1], totalshuffled[2], True, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BL3', 'BP2', 'CS2', 'CS5', 'BP5', 'BL4', 'CS3', 'BP3', 'BL5',\n",
       "       'BP1', 'BP4', 'BL1', 'CS4', 'BL2', 'CS1'], dtype='<U3')"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalshuffled[3]"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "136a1881476c47f8a0071c166718396a",
   "lastKernelId": "1c5b17de-86ea-4147-bc7c-c5f718ceb780"
  },
  "kernelspec": {
   "display_name": "Python 3.6 TDA",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
